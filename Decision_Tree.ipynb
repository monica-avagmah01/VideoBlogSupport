{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making intelligent decisions with Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction : \n",
    "\n",
    "In this blog we will discuss a Machine Learning Algorithm called Decision Tree. The goal of the blogpost is to get the beginners started with fundamental concepts of a Decision Tree and quickly help them to develop their first tree model in no time.  \n",
    "\n",
    "Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems.\n",
    "\n",
    "A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences. It is one way to display an algorithm that only contains conditional control statements.\n",
    "\n",
    "A decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an attribute , each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.\n",
    "\n",
    "It works for both categorical and continuous input and output variables.\n",
    "\n",
    "\n",
    "### Types of Decision Trees\n",
    "\n",
    "Types of decision tree is based on the type of target variable we have. It can be of two types:\n",
    "\n",
    "#### Categorical Variable Decision Tree:\n",
    "Decision Tree which has categorical target variable then it called as categorical variable decision tree. \n",
    "\n",
    "#### Continuous Variable Decision Tree:\n",
    "Decision Tree which has continuous target variable then it is called as Continuous Variable Decision Tree.\n",
    "\n",
    "\n",
    "#### Example:-\n",
    "Let’s say we have a problem to predict whether a bike is good or not . This can be judged by using decision tree classifier.\n",
    "However to qualify the bike into good or bad category mileage is an important factor. Mileage is measured using a contiguous value hence it can be measured using the decision tree regressor. \n",
    "\n",
    "<img src=\"./images/dt_.jpg\">\n",
    "\n",
    "<img src=\"./images/dt_2.gif\">\n",
    "\n",
    "\n",
    "### Important Terminology related to Decision Trees\n",
    "Let’s look at the basic terminology used with Decision trees:\n",
    "\n",
    "#### Root Node:\n",
    "It represents entire population or sample and this further gets divided into two or more homogeneous sets.\n",
    "\n",
    "#### Splitting:\n",
    "It is a process of dividing a node into two or more sub-nodes.\n",
    "\n",
    "#### Decision Node:\n",
    "When a sub-node splits into further sub-nodes, then it is called decision node.\n",
    "\n",
    "#### Leaf/ Terminal Node:\n",
    "Nodes do not split is called Leaf or Terminal node.\n",
    "\n",
    "#### Pruning:\n",
    "When we remove sub-nodes of a decision node, this process is called pruning. You can say opposite process of splitting.\n",
    "\n",
    "#### Branch / Sub-Tree:\n",
    "A sub-section of entire tree is called branch or sub-tree.\n",
    "\n",
    "#### Parent and Child Node:\n",
    "A node, which is divided into sub-nodes is called parent node of sub-nodes where as sub-nodes are the child of parent node.\n",
    "\n",
    "\n",
    "### How to split nodes\n",
    "The decision of making strategic splits heavily affects a tree’s accuracy. The decision criteria is different for classification and regression trees. Decision trees use multiple algorithms to decide to split a node in two or more sub-nodes. The creation of sub-nodes increases the homogeneity of resultant sub-nodes. In other words, we can say that purity of the node increases with respect to the target variable. Decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes.\n",
    "There are few algorithms to find optimum split. Let's look at the following to understand the mathematics behind. \n",
    "\n",
    "### Gini Index\n",
    "Gini index says, if we select two items from a population at random then they must be of same class and probability for this is 1 if population is pure.\n",
    "It works with categorical target variable “Success” or “Failure”. It performs only Binary splits **Higher the value of Gini higher the homogeneity**. CART (Classification and Regression Tree) uses Gini method to create binary splits.\n",
    "\n",
    "\n",
    "#### Steps to Calculate Gini for a split\n",
    "1.\tCalculate Gini for sub-nodes, using formula sum of square of probability for success and failure (p^2+q^2).\n",
    "2.\tCalculate Gini for split using weighted Gini score of each node of that split\t\n",
    "\n",
    "\n",
    "### Information gain\n",
    "We can derive information gain from entropy as **1- Entropy**. Entropy is a way measuring the amount of impurity in a given set of data. It is represented by a formula :\n",
    "<img src=\"./images/dt1.png\">\n",
    "\n",
    "where, 'p' is the probability of each individual classes in the split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID3 (Iterative Dichotomiser 3) algorithm uses entropy to calculate the homogeneity of a sample. If the sample is completely homogeneous the entropy is zero and if the sample is an equally divided it has entropy of one.\n",
    "\n",
    "Enough of theory now let’s dive into the implementation of Decision Tree.\n",
    "\n",
    "We will use implementation provided by the python machine learning framework known as scikit-learn.\n",
    "\t\n",
    " \n",
    "### Problem Statement : \n",
    "\n",
    "To build a Decision Tree model for prediction of car quality given other attributes about the car.\n",
    "\n",
    "### Data details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================\n",
    "Title: Car Evaluation Database\n",
    "==========================================\n",
    "\n",
    "1. The dataset is available at  http://archive.ics.uci.edu/ml/datasets/Car+Evaluation\n",
    "\n",
    "2. Sources:\n",
    "   (a) Creator: Marko Bohanec\n",
    "   (b) Donors: Marko Bohanec   (marko.bohanec@ijs.si), Blaz Zupan      (blaz.zupan@ijs.si)\n",
    "   (c) Date: June, 1997\n",
    "\n",
    "3. Past Usage:\n",
    "\n",
    "   The hierarchical decision model, from which this dataset is\n",
    "   derived, was first presented in \n",
    "\n",
    "   M. Bohanec and V. Rajkovic: Knowledge acquisition and explanation for\n",
    "   multi-attribute decision making. In 8th Intl Workshop on Expert\n",
    "   Systems and their Applications, Avignon, France. pages 59-78, 1988.\n",
    "\n",
    "   Within machine-learning, this dataset was used for the evaluation\n",
    "   of HINT (Hierarchy INduction Tool), which was proved to be able to\n",
    "   completely reconstruct the original hierarchical model. This,\n",
    "   together with a comparison with C4.5, is presented in\n",
    "\n",
    "   B. Zupan, M. Bohanec, I. Bratko, J. Demsar: Machine learning by\n",
    "   function decomposition. ICML-97, Nashville, TN. 1997 (to appear)\n",
    "\n",
    "4. Relevant Information Paragraph:\n",
    "\n",
    "   Car Evaluation Database was derived from a simple hierarchical\n",
    "   decision model originally developed for the demonstration of DEX\n",
    "   (M. Bohanec, V. Rajkovic: Expert system for decision\n",
    "   making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates\n",
    "   cars according to the following concept structure:\n",
    "\n",
    "   CAR                      car acceptability\n",
    "   \n",
    "   \n",
    "   . PRICE                  overall price\n",
    "   \n",
    "   \n",
    "   . . buying               buying price\n",
    "   \n",
    "   \n",
    "   . . maint                price of the maintenance\n",
    "   \n",
    "   \n",
    "   . TECH                   technical characteristics\n",
    "   \n",
    "   \n",
    "   . . COMFORT              comfort\n",
    "   \n",
    "   \n",
    "   . . . doors              number of doors\n",
    "   \n",
    "   \n",
    "   . . . persons            capacity in terms of persons to carry\n",
    "   \n",
    "   \n",
    "   . . . lug_boot           the size of luggage boot\n",
    "   \n",
    "   \n",
    "   . . safety               estimated safety of the car\n",
    "   \n",
    "\n",
    "   Input attributes are printed in lowercase. Besides the target\n",
    "   concept (CAR), the model includes three intermediate concepts:\n",
    "   PRICE, TECH, COMFORT. Every concept is in the original model\n",
    "   related to its lower level descendants by a set of examples (for\n",
    "   these examples sets see http://www-ai.ijs.si/BlazZupan/car.html).\n",
    "\n",
    "   The Car Evaluation Database contains examples with the structural\n",
    "   information removed, i.e., directly relates CAR to the six input\n",
    "   attributes: buying, maint, doors, persons, lug_boot, safety.\n",
    "\n",
    "   Because of known underlying concept structure, this database may be\n",
    "   particularly useful for testing constructive induction and\n",
    "   structure discovery methods.\n",
    "\n",
    "5. Number of Instances: 1728\n",
    "   (instances completely cover the attribute space)\n",
    "\n",
    "6. Number of Attributes: 6\n",
    "\n",
    "7. Attribute Values:\n",
    "\n",
    "   buying     :  v-high, high, med, low \n",
    "   \n",
    "   maint      :  v-high, high, med, low\n",
    "   \n",
    "   doors       : 2, 3, 4, 5-more\n",
    "   \n",
    "   persons     : 2, 4, more\n",
    "   \n",
    "   lug_boot    : small, med, big\n",
    "   \n",
    "   safety      : low, med, high\n",
    "   \n",
    "8. Missing Attribute Values: none\n",
    "\n",
    "9. Class Distribution (number of instances per class)\n",
    "\n",
    "class      N          N[%]\n",
    "\n",
    "unacc     1210     (70.023 %) \n",
    "   \n",
    "acc        384     (22.222 %) \n",
    "   \n",
    "good        69     ( 3.993 %) \n",
    "   \n",
    "v-good      65     ( 3.762 %)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools to be used : \n",
    "\n",
    "Numpy,pandas,scikit-learn\n",
    "\n",
    "### Python Implementation with code :\n",
    "\n",
    "Import necessary libraries \n",
    "\n",
    "Import the necessary modules from specific libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data set\n",
    "Use pandas module to read the bike data from the file system. Check few records of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('~/data/car.data',names=['buying','maint','doors','persons','lug_boot','safety','class'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check few information about the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      "buying      1728 non-null object\n",
      "maint       1728 non-null object\n",
      "doors       1728 non-null object\n",
      "persons     1728 non-null object\n",
      "lug_boot    1728 non-null object\n",
      "safety      1728 non-null object\n",
      "class       1728 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train data set has 1728 rows and 7 columns.\n",
    "There are no missing values in the dataset\n",
    "\n",
    "### Identify the target variable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'],class_names = pd.factorize(data['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is marked as class in the dataframe. The values are present in  string format. However the algorithm requires the variables to be coded into its equivalent integer codes. We can convert the string categorical values into a integer code using factorize method of the pandas library.\n",
    "\n",
    "Let’s check the encoded values now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['unacc', 'acc', 'vgood', 'good'], dtype='object')\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(class_names)\n",
    "print(data['class'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the values has been encoded into 4 different numeric labels.\n",
    "\n",
    "### Identify the predictor variables and encode any string variables to equivalent integer codes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety  class\n",
       "0       0      0      0        0         0       0      0\n",
       "1       0      0      0        0         0       1      0\n",
       "2       0      0      0        0         0       2      0\n",
       "3       0      0      0        0         1       0      0\n",
       "4       0      0      0        0         1       1      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['buying'],_ = pd.factorize(data['buying'])\n",
    "data['maint'],_ = pd.factorize(data['maint'])\n",
    "data['doors'],_ = pd.factorize(data['doors'])\n",
    "data['persons'],_ = pd.factorize(data['persons'])\n",
    "data['lug_boot'],_ = pd.factorize(data['lug_boot'])\n",
    "data['safety'],_ = pd.factorize(data['safety'])\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data types now :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      "buying      1728 non-null int64\n",
      "maint       1728 non-null int64\n",
      "doors       1728 non-null int64\n",
      "persons     1728 non-null int64\n",
      "lug_boot    1728 non-null int64\n",
      "safety      1728 non-null int64\n",
      "class       1728 non-null int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 94.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is now converted in integer form.\n",
    "\n",
    "### Select the predictor feature and select the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data randomly into 70% training and 30% test\n",
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training / model fitting \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the decision tree with entropy for information gain\n",
    "dtree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters study :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 96\n",
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# use the model to make predictions with the test data\n",
    "y_pred = dtree.predict(X_test)\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred).sum()\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the algorithm was able to achieve classification accuracy of 82% on the held out set. Only 96 samples were misclassified.\n",
    "\n",
    "### Visualization of the decision graph :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the .exe file for Windows/Mac/Linux from the below related links\n",
    "https://graphviz.gitlab.io/_pages/Download/\n",
    "https://graphviz.gitlab.io/_pages/Download/Download_windows.html\n",
    "\n",
    "Include the path where graphviz has been installed in the Path environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "feature_names = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['0','1','2','3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(dtree, out_file=None, filled=True, rounded=True,feature_names=feature_names ,  \n",
    "                                class_names=class_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"506pt\" height=\"433pt\"\n",
       " viewBox=\"0.00 0.00 506.00 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-429 502,-429 502,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.615686\" stroke=\"#000000\" d=\"M229,-425C229,-425 83,-425 83,-425 77,-425 71,-419 71,-413 71,-413 71,-354 71,-354 71,-348 77,-342 83,-342 83,-342 229,-342 229,-342 235,-342 241,-348 241,-354 241,-354 241,-413 241,-413 241,-419 235,-425 229,-425\"/>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">safety &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.203</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1209</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [847, 269, 49, 44]</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M128,-298.5C128,-298.5 12,-298.5 12,-298.5 6,-298.5 0,-292.5 0,-286.5 0,-286.5 0,-242.5 0,-242.5 0,-236.5 6,-230.5 12,-230.5 12,-230.5 128,-230.5 128,-230.5 134,-230.5 140,-236.5 140,-242.5 140,-242.5 140,-286.5 140,-286.5 140,-292.5 134,-298.5 128,-298.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 411</text>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [411, 0, 0, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M125.9214,-341.8796C117.8157,-330.6636 109.0347,-318.5131 100.8857,-307.2372\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.4932,-304.8698 94.799,-298.8149 97.8197,-308.9701 103.4932,-304.8698\"/>\n",
       "<text text-anchor=\"middle\" x=\"90.8258\" y=\"-319.7972\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.317647\" stroke=\"#000000\" d=\"M316,-306C316,-306 170,-306 170,-306 164,-306 158,-300 158,-294 158,-294 158,-235 158,-235 158,-229 164,-223 170,-223 170,-223 316,-223 316,-223 322,-223 328,-229 328,-235 328,-235 328,-294 328,-294 328,-300 322,-306 316,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">persons &lt;= 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.483</text>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 798</text>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [436, 269, 49, 44]</text>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M186.4284,-341.8796C192.8811,-333.0534 199.757,-323.6485 206.4113,-314.5466\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"209.3653,-316.4364 212.4417,-306.2981 203.7144,-312.3051 209.3653,-316.4364\"/>\n",
       "<text text-anchor=\"middle\" x=\"216.2792\" y=\"-327.3018\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M214,-179.5C214,-179.5 98,-179.5 98,-179.5 92,-179.5 86,-173.5 86,-167.5 86,-167.5 86,-123.5 86,-123.5 86,-117.5 92,-111.5 98,-111.5 98,-111.5 214,-111.5 214,-111.5 220,-111.5 226,-117.5 226,-123.5 226,-123.5 226,-167.5 226,-167.5 226,-173.5 220,-179.5 214,-179.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 263</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [263, 0, 0, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"156\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M212.5716,-222.8796C204.2913,-211.5536 195.3143,-199.2748 187.0026,-187.9058\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"189.8147,-185.822 181.0874,-179.8149 184.1639,-189.9533 189.8147,-185.822\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#47e539\" fill-opacity=\"0.266667\" stroke=\"#000000\" d=\"M402,-187C402,-187 256,-187 256,-187 250,-187 244,-181 244,-175 244,-175 244,-116 244,-116 244,-110 250,-104 256,-104 256,-104 402,-104 402,-104 408,-104 414,-110 414,-116 414,-116 414,-175 414,-175 414,-181 408,-187 402,-187\"/>\n",
       "<text text-anchor=\"middle\" x=\"329\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">buying &lt;= 1.5</text>\n",
       "<text text-anchor=\"middle\" x=\"329\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.638</text>\n",
       "<text text-anchor=\"middle\" x=\"329\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 535</text>\n",
       "<text text-anchor=\"middle\" x=\"329\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [173, 269, 49, 44]</text>\n",
       "<text text-anchor=\"middle\" x=\"329\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M273.0786,-222.8796C279.4572,-214.0534 286.254,-204.6485 292.8319,-195.5466\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"295.7723,-197.4532 298.793,-187.2981 290.0988,-193.353 295.7723,-197.4532\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.015686\" stroke=\"#000000\" d=\"M305.5,-68C305.5,-68 174.5,-68 174.5,-68 168.5,-68 162.5,-62 162.5,-56 162.5,-56 162.5,-12 162.5,-12 162.5,-6 168.5,0 174.5,0 174.5,0 305.5,0 305.5,0 311.5,0 317.5,-6 317.5,-12 317.5,-12 317.5,-56 317.5,-56 317.5,-62 311.5,-68 305.5,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"240\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.0</text>\n",
       "<text text-anchor=\"middle\" x=\"240\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 278</text>\n",
       "<text text-anchor=\"middle\" x=\"240\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [140, 138, 0, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"240\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M295.8597,-103.9815C288.597,-94.8828 280.9017,-85.242 273.6204,-76.1199\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"276.3234,-73.8958 267.3495,-68.2637 270.8525,-78.2627 276.3234,-73.8958\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#47e539\" fill-opacity=\"0.396078\" stroke=\"#000000\" d=\"M486,-68C486,-68 348,-68 348,-68 342,-68 336,-62 336,-56 336,-56 336,-12 336,-12 336,-6 342,0 348,0 348,0 486,0 486,0 492,0 498,-6 498,-12 498,-12 498,-56 498,-56 498,-62 492,-68 486,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"417\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.768</text>\n",
       "<text text-anchor=\"middle\" x=\"417\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 257</text>\n",
       "<text text-anchor=\"middle\" x=\"417\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [33, 131, 49, 44]</text>\n",
       "<text text-anchor=\"middle\" x=\"417\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M361.768,-103.9815C368.949,-94.8828 376.5579,-85.242 383.7574,-76.1199\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"386.5099,-78.2818 389.9578,-68.2637 381.0151,-73.9451 386.5099,-78.2818\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f71482036a0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
